{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('base': conda)",
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "from soylemma import Lemmatizer\n",
    "from soynlp.noun import LRNounExtractor_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance = \"엄마랑 신나는 밀가루 놀이 꾹 꾹 꾹 꾹 한번 눌러볼래\"\n",
    "\n",
    "with open('../semnet/wordlist.txt', 'r') as f:\n",
    "    raw = f.read()\n",
    "    wordlist = raw.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "tagger = Kkma()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def parse_utterance(u):\n",
    "    ''' Parses the utterance and yields\n",
    "        1) nouns\n",
    "        2) lemmatized verbs and adjectives\n",
    "    '''\n",
    "    results = []\n",
    "    morphemes = tagger.pos(u)\n",
    "\n",
    "    nouns = tagger.nouns(u)\n",
    "    verbs = [m[0] for m in morphemes if 'VV' in m[1]]\n",
    "    other = pass # TODO\n",
    "\n",
    "    results.extend(nouns)\n",
    "    results.extend([lemmatizer.lemmatize(v) for v in verbs])\n",
    "    results.extend([lemmatizer.lemmatize(w) for w in other])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatized = [lemmatizer.lemmatize(x) for x in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = utterance\n",
    "morphemes = tagger.pos(u)\n",
    "\n",
    "nouns = tagger.nouns(u)\n",
    "verbs = [m[0] for m in morphemes if 'V' in m[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'엄마랑 신나는 밀가루 놀이 꾹 꾹 꾹 꾹 한번 눌러볼래'"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['눌르', '보']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter()\n",
    "twitter.nouns(transcript_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = '../../model_weights/pos.vec'\n",
    "pos_vectors = KeyedVectors.load_word2vec_format(pretrained_embeddings, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter()\n",
    "\n",
    "def normalize(array):\n",
    "    norm = np.linalg.norm(array)\n",
    "    return array / norm\n",
    "\n",
    "def create_word_vector(word):\n",
    "    pos_list = twitter.pos(word, norm=True)\n",
    "    word_vector = np.sum([pos_vectors.word_vec(str(pos).replace(\" \", \"\")) for pos in pos_list], axis=0)\n",
    "    return normalize(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = create_word_vector('강아지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = twitter.pos('강아지', norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = str(pos_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vectors.most_similar(query, topn=10, indexer=indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pruned_vectors():\n",
    "    ''' Saves a new file of keyed embeddings corresponding to only\n",
    "        the words in the basic word list.\n",
    "    '''\n",
    "    with open('../semnet/wordlist.txt', 'r') as f:\n",
    "        raw = f.read()\n",
    "        basic_words = raw.split()\n",
    "    \n",
    "    with open('../semnet/basic_word_embeddings.vec', 'w') as f:\n",
    "        for word in basic_words:\n",
    "            try:\n",
    "                vec = create_word_vector(word)\n",
    "                f.write('{} {}\\n'.format(word, ' '.join(vec.astype('str'))))\n",
    "            except KeyError:\n",
    "                print('word not found: {}'.format(word))\n",
    "\n",
    "get_pruned_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_vectors = KeyedVectors.load_word2vec_format('../semnet/basic_word_embeddings.vec', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '엄마'\n",
    "basic_vectors.most_similar(positive=query, topn=10)"
   ]
  }
 ]
}