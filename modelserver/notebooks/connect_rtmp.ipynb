{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 16, 8] {'32': {'SCALES': (32, 16), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '16': {'SCALES': (8, 4), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}, '8': {'SCALES': (2, 1), 'BASE_SIZE': 16, 'RATIOS': (1.0,), 'ALLOWED_BORDER': 9999}}\n",
      "use_landmarks True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import imageio\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "import PIL\n",
    "\n",
    "import IPython\n",
    "\n",
    "\n",
    "from wrappers.face_detector2 import FaceDetector\n",
    "from wrappers.gaze_follower import GazeFollower\n",
    "from wrappers.object_detector import ObjectDetector\n",
    "import plotter\n",
    "from utils import Fps\n",
    "\n",
    "from imagestream.py import ImageStream\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def imshow_as_jpeg(image, scale=1.0):\n",
    "    f = BytesIO()\n",
    "    width = int(image.shape[1] * scale)\n",
    "    height = int(image.shape[0] * scale)\n",
    "    resized = cv2.resize(image, (width, height))\n",
    "    PIL.Image.fromarray(resized).save(f, 'jpeg')\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "\n",
    "face_detector = FaceDetector()\n",
    "object_detector = ObjectDetector()\n",
    "gaze_follower = GazeFollower('../model_weights/visatt.pt')\n",
    "id_class_mappings = object_detector.id_to_classname_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-552d81661576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mfps_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#     print(len(frames))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# most recent?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/modelserver/src/imagestream.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m         '''\n\u001b[1;32m     69\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m# print('acquired lock in dump')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# video = cv2.VideoCapture('../data/test_video_11.mkv')\n",
    "addr = \"rtmp://video:1935/captivate/test\"\n",
    "# video = cv2.VideoCapture(addr)\n",
    "# video.isOpened()\n",
    "imagestream = ImageStream(addr, buffer_length=1)\n",
    "\n",
    "\n",
    "def infer_single_frame(frame, fps_counter):\n",
    "    fps = fps_counter.count()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_pil = PIL.Image.fromarray(frame.astype('uint8'), 'RGB')\n",
    "    \n",
    "    plotter.cv2_write_text(frame, 'fps: {:.2f}'.format(fps), (10, 30))\n",
    "    \n",
    "    face_bboxes = face_detector.predict(frame)\n",
    "\n",
    "    plotter.cv2_draw_face_bboxes(frame, face_bboxes)\n",
    "    \n",
    "    objects = object_detector.predict(frame)\n",
    "\n",
    "    instances = objects['instances'] # only key\n",
    "    fields = instances.get_fields()\n",
    "    object_bboxes = fields['pred_boxes'].tensor.cpu().numpy()\n",
    "    class_ids = fields['pred_classes']\n",
    "    scores = fields['scores'].cpu().numpy()\n",
    "\n",
    "    classes = list(map(lambda x: id_class_mappings[x], class_ids))\n",
    "\n",
    "    plotter.cv2_draw_objects(frame, object_bboxes, classes, scores)\n",
    "    \n",
    "    if face_bboxes != []:\n",
    "        for face_bbox in face_bboxes:\n",
    "            focus_point = gaze_follower.predict_gaze(frame_pil, face_bbox)\n",
    "            plotter.cv2_draw_gaze(frame, face_bbox, focus_point)\n",
    "\n",
    "    imshow_as_jpeg(frame, 0.6)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "\n",
    "imagestream.start()\n",
    "fps_counter = Fps()\n",
    "while(1):\n",
    "    frames = imagestream.dump()\n",
    "#     print(len(frames))\n",
    "    frame = frames[-1] # most recent?\n",
    "    infer_single_frame(frame, fps_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single frame\n",
    "read, frame = video.read()\n",
    "imshow_as_jpeg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_to_image(fig, dpi=180):\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format=\"jpg\", dpi=dpi)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    IPython.display.display(IPython.display.Image(data=buf.getvalue()))\n",
    "#     img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "#     buf.close()\n",
    "#     img = cv2.imdecode(img_arr, 1)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show video using iPython.display & jpeg conversion\n",
    "\n",
    "# video = cv2.VideoCapture('../data/test_video_11.mkv')\n",
    "# video.isOpened()\n",
    "\n",
    "addr = \"rtmp://video:1935/live/test\"\n",
    "video = cv2.VideoCapture(addr)\n",
    "video.isOpened()\n",
    "\n",
    "fps_counter = Fps()\n",
    "\n",
    "# out_writer = imageio.get_writer('out_test.mp4', fps=29.7)\n",
    "\n",
    "while video.isOpened():\n",
    "    fps = fps_counter.count()\n",
    "    \n",
    "    read, frame = video.read()\n",
    "    \n",
    "    if read is False:\n",
    "        print('read is False')\n",
    "        break\n",
    "        \n",
    "    if frame is None:\n",
    "        print('frame is None')\n",
    "        break\n",
    "        \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plotter.cv2_write_text(frame, 'fps: {:.2f}'.format(fps), (50,200))\n",
    "    imshow_as_jpeg(frame, 0.2)\n",
    "    \n",
    "#     out_writer.append_data(frame)\n",
    "    \n",
    "#     print(fps)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "video.release()\n",
    "# out_writer.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr = \"rtmp://video:1935/live/test\"\n",
    "video = cv2.VideoCapture(addr)\n",
    "video.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_class_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single frame test\n",
    "\n",
    "read, frame = video.read()\n",
    "bboxes = face_detector.predict(frame)\n",
    "frame_pil = PIL.Image.fromarray(frame.astype('uint8'), 'RGB')\n",
    "\n",
    "plotter.cv2_draw_bboxes(frame, bboxes)\n",
    "bbox = bboxes[0]\n",
    "\n",
    "focus_point = gaze_follower.predict_gaze(frame_pil, bbox)\n",
    "\n",
    "plotter.cv2_draw_gaze(frame, bbox, focus_point)\n",
    "\n",
    "imshow_as_jpeg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread('../data/baby_room_2.jpg')\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "objects = object_detector.predict(frame)\n",
    "\n",
    "instances = objects['instances'] # only key\n",
    "fields = instances.get_fields()\n",
    "bboxes = fields['pred_boxes'].tensor.cpu().numpy()\n",
    "class_ids = fields['pred_classes']\n",
    "scores = fields['scores']\n",
    "\n",
    "classes = list(map(lambda x: id_class_mappings[x], class_ids))\n",
    "\n",
    "plotter.cv2_draw_objects(frame, bboxes, classes)\n",
    "\n",
    "imshow_as_jpeg(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matplotlib: just rendering is 1~2 fps\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "ax.axis(False)\n",
    "\n",
    "fps_counter = Fps()\n",
    "\n",
    "while video.isOpened():\n",
    "    fps = fps_counter.count()\n",
    "    read, frame = video.read()\n",
    "    if read is False:\n",
    "        print('read is False')\n",
    "        break\n",
    "        \n",
    "    if frame is None:\n",
    "        print('frame is None')\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(fps)\n",
    "    \n",
    "#     bboxes = face_detector.predict(frame)\n",
    "    \n",
    "#     if bboxes == []:\n",
    "# #         plt.imshow(frame)\n",
    "# #         figure_to_image(fig)\n",
    "#         continue\n",
    "        \n",
    "    # PIL conversion has trivial overhead\n",
    "#     image_pil = PIL.Image.fromarray(frame.astype('uint8'), 'RGB')\n",
    "#     bbox = bboxes[0]\n",
    "#     norm_map, raw_hm, inout = gaze_follower.predict_gaze(image_pil, bbox)\n",
    "    \n",
    "    # plot\n",
    "#     fig = plotter.plot_face_bboxes(frame, bboxes, plot_image=True)\n",
    "#     plotter.plot_heatmap(frame, norm_map, raw_hm, bbox, inout, plot_image=False)\n",
    "#     figure_to_image(fig)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = None\n",
    "\n",
    "while(1):\n",
    "    read, frame = video.read()\n",
    "    \n",
    "    if not read:\n",
    "        print('not read')\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "        \n",
    "    if image is None:\n",
    "        image = plt.imshow(frame)\n",
    "    else:\n",
    "        image.set_data(frame)\n",
    "        \n",
    "    plt.pause(0.01)\n",
    "   \n",
    "    plt.draw()\n",
    "    \n",
    "    time.sleep(1)\n",
    "#     clear_output(wait=True)\n",
    "    \n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
